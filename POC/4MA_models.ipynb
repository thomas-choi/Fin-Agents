{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a7403f9-e6cb-4b71-8fa9-0e954899b308",
   "metadata": {},
   "outputs": [],
   "source": [
    "from MA4Strategy import generate_candlestick_with_emas, load_data, evaluate_model\n",
    "from MA4Strategy import build_cnn_model, build_cnn_lstm_model, build_dense_model, plot_accuracy, cal_accuracy\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66730c28-0d18-420b-9844-9d1d6b3c44be",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_file = \"4MAs_result.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a081759-ef83-484e-b2da-6acdf66c1689",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(ticker, window_days, alpha, epochs, predict_days, batch_size, result_df):\n",
    "    # if model file exist, skip the process\n",
    "    model_file = os.path.join(\"models\", f\"{ticker}_{window_days}_{alpha}_{epochs}_{predict_days}_{batch_size}.pkl\")\n",
    "    if os.path.exists(model_file):\n",
    "        print(f\"{model_file} model exist\")\n",
    "        return result_df\n",
    "\n",
    "    # Generate and split data\n",
    "    train_p = f\"train_{ticker}_{window_days}_{alpha}_{epochs}_{predict_days}_{batch_size}\"\n",
    "    test_p = f\"test_{ticker}_{window_days}_{alpha}_{epochs}_{predict_days}_{batch_size}\"\n",
    "    train_charts, train_labels, test_charts, test_labels, fulldata = generate_candlestick_with_emas(ticker, predict_days, window_days, alpha,\n",
    "                                                                                                   train_p, test_p)\n",
    "\n",
    "    if not train_charts or not test_charts:\n",
    "        print(\"No charts generated, exiting.\")\n",
    "        return result_df\n",
    "        \n",
    "    em_y = fulldata['EMStrend'].dropna()\n",
    "    print(len(em_y))\n",
    "    lb_y = fulldata['Labels'].dropna()\n",
    "    print(len(lb_y))\n",
    "\n",
    "    # Load training and testing data\n",
    "    X_train, y_train = load_data(f\"{train_p}_metadata.csv\")\n",
    "    X_test, y_test = load_data(f\"{test_p}_metadata.csv\")\n",
    "    \n",
    "    # print(\"Trainning data:  \", X_train, \",\", y_train)\n",
    "    # print(\"Testing data:  \", X_test, \",\", y_test)\n",
    "    \n",
    "    if X_train.size == 0 or X_test.size == 0:\n",
    "        print(\"No valid images processed, exiting.\")\n",
    "        return result_df\n",
    "        \n",
    "    # Define models to train\n",
    "    models = [build_cnn_model(), build_cnn_lstm_model(), build_dense_model()]\n",
    "    \n",
    "    # Train and evaluate each model\n",
    "    for model, model_name in models:\n",
    "        print(f\"\\nTraining {model_name}...\")\n",
    "        history = model.fit(X_train, y_train, epochs=epochs, validation_split=0.2, batch_size=batch_size, verbose=1)\n",
    "        plot_accuracy(ticker, history, model_name)\n",
    "        acc, prec, recall, f1 = evaluate_model(ticker, model, X_test, y_test, model_name)\n",
    "        # Append the row\n",
    "        new_row =[ticker,model_name,window_days, alpha, epochs, predict_days, batch_size,acc, prec, recall, f1]\n",
    "        result_df.loc[len(result_df)] = new_row\n",
    "        with open(model_file, 'wb') as file:\n",
    "            pickle.dump(model, file)   \n",
    "        result_df.to_csv(result_file, index=False)\n",
    "        tf.keras.backend.clear_session()\n",
    "\n",
    "    trend_mapping = {\"UP\": 1, \"DOWN\": 2, \"SIDEWAY\": 3}\n",
    "    em_y = fulldata['EMStrend'].dropna().to_list()\n",
    "    lb_y = fulldata['Labels'].dropna().to_list()\n",
    "    emyy = [trend_mapping[em] for em in em_y]\n",
    "    lbyy = [trend_mapping[em] for em in lb_y]\n",
    "\n",
    "    acc, prec, recall, f1 = cal_accuracy(ticker, lbyy, emyy, model_name)\n",
    "    new_row =[ticker,'4MAs',window_days, alpha, epochs, predict_days, batch_size,acc, prec, recall, f1]\n",
    "    result_df.loc[len(result_df)] = new_row\n",
    "    result_df.to_csv(result_file, index=False)\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "734146bf-bc31-48ea-b013-f4daaa5f68f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers = ['^HSI','SPY','NVDA','TSLA']\n",
    "window_days_l = [25, 50, 75]\n",
    "alpha_l = [0.4, 0.5, 0.6]\n",
    "epochs_l = [25,50]\n",
    "predict_days_l = [5,8]\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "399077a3-bdc3-42d0-a2db-45ce8db03328",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "column_names=['ticker','model','window_days','alpha','epochs','predict_days','batch_size','accuracy','precision','recall','f1']\n",
    "\n",
    "if os.path.exists(result_file):\n",
    "    print(f\"Reload {result_file} for append result.\")\n",
    "    result = pd.read_csv(result_file)\n",
    "else:\n",
    "    print(f\"Create {result_file}\")\n",
    "    result=pd.DataFrame(columns=column_names)\n",
    "\n",
    "for ticker in tickers:\n",
    "    for window_days in window_days_l:\n",
    "        for alpha in alpha_l:\n",
    "            for epochs in epochs_l:\n",
    "                for predict_days in predict_days_l:\n",
    "                    print( window_days, alpha, epochs, predict_days)\n",
    "                    result = main(ticker, window_days, alpha, epochs, predict_days, batch_size, result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c5dab3-537e-4b33-b08a-a3b3adb8b69c",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac139b0-c168-4ee8-bd4c-869b3ced43be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d0e262-4fd4-4fc5-b17e-d54e51938bd6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8351aea4-eabf-4153-a516-fbae22a191bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
